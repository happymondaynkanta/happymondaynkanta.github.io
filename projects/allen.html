<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Recognition of Images from CIFAR-10 Dataset using Deep Learning | Li Qingyu</title>
    <link rel="stylesheet" href="https://happymondaynkanta.github.io/css/semantic.min.css">
    <style>
        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
        }
        .project-header {
            text-align: center;
            background-color: #6a0572;
            color: #fff;
            padding: 30px 10px;
            font-size: 2.2em;
            letter-spacing: 0.5px;
        }
        .content-section {
            max-width: 860px;
            margin: 30px auto;
            padding: 25px;
            background-color: #fefefe;
            border-radius: 10px;
            box-shadow: 0 0 12px rgba(0, 0, 0, 0.1);
            line-height: 1.75;
            color: #333;
        }
        h2 {
            color: #6a0572;
        }
        p {
            text-align: justify;
        }
        ul {
            margin-left: 20px;
        }
        .student-profile {
            background-color: #f3e8ff;
            padding: 15px;
            border-left: 5px solid #6a0572;
            margin-top: 30px;
            font-style: italic;
        }
        .button-group {
            text-align: center;
            margin: 30px 0;
        }
        .button-group a {
            padding: 12px 24px;
            margin: 6px;
            background-color: #6a0572;
            color: #fff;
            border-radius: 5px;
            text-decoration: none;
            transition: background-color 0.3s ease;
        }
        .button-group a:hover {
            background-color: #4e0356;
        }
        footer {
            text-align: center;
            background-color: #2c003e;
            color: #eee;
            padding: 15px;
            font-size: 0.9em;
            margin-top: 50px;
        }
    </style>
</head>
<body>

<div class="project-header">
    Recognition of Images from CIFAR-10 Dataset using Deep Learning Network
</div>

<div class="content-section">
    <h2>Abstract</h2>
    <p>
        This project implements a deep learning image classification system using a fine-tuned VGG19 model on the CIFAR-10 dataset. The system was trained to identify 10 classes of images, achieving a training accuracy of 99% and validation accuracy of 88%. The project further deploys a Flask-based GUI for real-time image recognition, showcasing practical application of AI in vision tasks. This confirms the strength of deep learning models, particularly convolutional neural networks, in real-world image recognition scenarios.
    </p>

    <h2>Key Contributions</h2>
    <ul>
        <li>Implemented transfer learning using the VGG19 architecture adapted to CIFAR-10 dataset.</li>
        <li>Achieved 88% accuracy on validation images, indicating robust performance.</li>
        <li>Designed and deployed a functional Flask web interface for interactive image prediction.</li>
        <li>Visualized training accuracy/loss trends and confusion matrix for model evaluation.</li>
    </ul>

    <h2>Conclusion</h2>
    <p>
        The study demonstrates that deep convolutional networks like VGG19 are effective in image classification tasks when properly trained and fine-tuned. The project highlights the real-world feasibility of applying pre-trained models in new domains through transfer learning and custom GUI deployment. It offers promising directions for machine vision applications in various sectors.
    </p>

    <h2>Limitation</h2>
    <p>
        The model, while accurate, remains constrained by dataset noise and low resolution of CIFAR-10 images. Moreover, deployment is limited by the computational cost of real-time CNN inference and dataset-specific generalizability.
    </p>

    <h2>Future Work</h2>
    <p>
        Future enhancements will explore the use of deeper ensemble architectures and higher-resolution datasets. Incorporating autoML tools and expanding the interface for multi-model comparison will be considered to improve scalability and accuracy.
    </p>

    <div class="student-profile">
        üë®‚Äçüíª <strong>Researcher:</strong> Li Qingyu (Allen) research interest lies in deep learning and computer vision. Under the supervision of Dr. Happy Nkanta Monday,
        Li demonstrated strong analytical and development skills by building an end-to-end image classification system with a web interface.
    </div>

    <div class="button-group">
        <a href="https://happymondaynkanta.github.io/poster/Allen_poster.pdf" download>üìÑ Download Poster</a>
        <a href="https://pan.baidu.com/s/1qbqNZbIO2ZabaUxk5NA-vw?pwd=47dk" target="_blank">üìÅ Access Dataset</a>
    </div>
</div>

<footer>
    üí° Author: Li Qingyu (Allen) | Supervised by Dr. Happy Nkanta Monday | üîç AI for Vision ‚Äì Insight that Saves Sight
</footer>

<script src="https://happymondaynkanta.github.io/css/semantic.min.js"></script>
</body>
</html>
